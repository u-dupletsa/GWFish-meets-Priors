{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get posterior samples we need to do Fisher analysis of our events and then apply priors in post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LVK_DATA = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/GWTC_LVK_data/'\n",
    "PATH_TO_INFO = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/info/'\n",
    "PATH_TO_RESULTS = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/results/'\n",
    "PATH_TO_INJECTIONS = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/injections/'\n",
    "PATH_TO_YAML = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/yamls/'\n",
    "PATH_TO_PSD = '/Users/ulyana/Documents/GSSI/PhD Projects/GWTC_results/gwtc_psds/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with BBH data and we take the median as the value to inject in `gwfish`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = 'IMRPhenomXPHM'\n",
    "estimator = 'median'\n",
    "params = ['chirp_mass', 'mass_ratio', 'luminosity_distance', 'dec', 'ra', 'theta_jn', 'psi', 'phase', \n",
    "            'geocent_time', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the events' list for which we have the analytic prior from the LVK analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = np.loadtxt(PATH_TO_INFO + 'events_wf_%s_priors_%s.txt' %(estimator, waveform), dtype=str)\n",
    "with open(PATH_TO_INFO + 'detectors_dictionary.pkl', 'rb') as f:\n",
    "    detectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the folder where to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = 'gwfish_medians'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fisher parameters are the same as the injection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_parameters = ['chirp_mass', 'mass_ratio', 'luminosity_distance', 'dec', 'ra', 'theta_jn', 'psi', 'phase', \n",
    "            'geocent_time', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl']\n",
    "gwfish_analysis(PATH_TO_INJECTIONS, PATH_TO_YAML, PATH_TO_RESULTS + results_folder + '/', \n",
    "                events, waveform, estimator, detectors, fisher_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to produce 3 different sets of posterior samples:\n",
    "1. LVK posterior samples as obtained using full Bayesian analysis\n",
    "2. Fisher matrix posterior samples, sampled from the multi-variate Gaussian likelihood approximation\n",
    "3. Prior-informed Fisher matrix posterior samples, obtained sampling from the truncated multi-variate Gaussian likelihood where each sample is weighted by its prior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LVK samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_len = {}\n",
    "for event in events:\n",
    "    samples_lvk = get_lvk_samples(PATH_TO_LVK_DATA, event, params)\n",
    "    samples_lvk_df = pd.DataFrame(samples_lvk)\n",
    "    samples_len[event] = len(samples_lvk_df)\n",
    "    samples_lvk_df.to_hdf(PATH_TO_RESULTS + 'posterior_samples/lvk_samples/lvk_samples_%s.hdf5' %event, mode='w', key='root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_INFO + 'lvk_samples_len_%s.pkl' %waveform, 'wb') as f:\n",
    "        pickle.dump(samples_len, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWFish samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_INFO + 'lvk_samples_len_%s.pkl' %waveform, 'rb') as f:\n",
    "    samples_len = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_INFO + 'detectors_dictionary.pkl', 'rb') as f:\n",
    "    detectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_errs = ['snr', 'chirp_mass', 'mass_ratio', 'luminosity_distance', 'dec', 'ra', 'theta_jn',\n",
    "        'psi', 'phase', 'geocent_time', 'a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl',\n",
    "        'err_chirp_mass', 'err_mass_ratio', 'err_luminosity_distance', 'err_dec', 'err_ra',\n",
    "        'err_theta_jn', 'err_psi', 'err_phase', 'err_geocent_time', 'err_a_1', 'err_a_2', 'err_tilt_1',\n",
    "        'err_tilt_2', 'err_phi_12', 'err_phi_jl', 'err_sky_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # for reproducibility\n",
    "\n",
    "for event in events:\n",
    "    label_err = get_label(detectors, event, estimator, 0, 'errors')\n",
    "    label_cov = get_label(detectors, event, estimator, 0, 'inv_fishers')\n",
    "    data = pd.read_csv(PATH_TO_RESULTS + 'gwfish_medians/' + event + '/' + label_err, names = lbs_errs, delimiter=' ', skiprows=1)\n",
    "    mns = data[params].iloc[0].to_numpy()\n",
    "    cov = np.load(PATH_TO_RESULTS + 'gwfish_medians/' + event + '/' + label_cov)[0, :, :]\n",
    "    samples = np.random.multivariate_normal(mns, cov, samples_len[event])\n",
    "    samples_df = pd.DataFrame(samples, columns = params)\n",
    "    samples_df.to_hdf(PATH_TO_RESULTS + 'posterior_samples/fisher_samples/fisher_samples_%s_%s.hdf5' %(estimator, event), mode='w', key='root')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher + Priors samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_INFO + 'chirp_mass_priors_%s.pkl' %waveform, 'rb') as f:\n",
    "    chirp_mass_priors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_INFO + 'geocent_time_priors_%s.pkl' %waveform, 'rb') as f:\n",
    "    geocent_time_priors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build priors range dictionary\n",
    "my_priors = {}\n",
    "for event in events:\n",
    "    event_dict = {\n",
    "        'chirp_mass': np.array([float(chirp_mass_priors[event][0]), float(chirp_mass_priors[event][1])]),\n",
    "        'mass_ratio': np.array([0.05, 1.0]),\n",
    "        'luminosity_distance': np.array([10, 10000]),\n",
    "        'dec': np.array([-np.pi/2, np.pi/2]),\n",
    "        'ra': np.array([0, 2*np.pi]),\n",
    "        'theta_jn': np.array([0, np.pi]),\n",
    "        'psi': np.array([0, np.pi]),\n",
    "        'phase': np.array([0, 2*np.pi]),\n",
    "        'geocent_time': np.array([float(geocent_time_priors[event][0]), float(geocent_time_priors[event][1])]),\n",
    "        'a_1': np.array([0, 0.99]),\n",
    "        'a_2': np.array([0, 0.99]),\n",
    "        'tilt_1': np.array([0, np.pi]),\n",
    "        'tilt_2': np.array([0, np.pi]),\n",
    "        'phi_12': np.array([0, 2*np.pi]),\n",
    "        'phi_jl': np.array([0, 2*np.pi])\n",
    "    }\n",
    "    my_priors[event] = event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_array = np.array([-np.inf, 0, 0, -np.pi/2, 0, 0, 0, 0, -np.inf, 0, 0, 0, 0, 0, 0])\n",
    "max_array = np.array([np.inf, 1, 20000, np.pi/2, 2*np.pi, np.pi, np.pi, 2*np.pi, np.inf, 1, 1, np.pi, np.pi, 2*np.pi, 2*np.pi])\n",
    "\n",
    "for event in events:\n",
    "    label_err = get_label(detectors, event, estimator, 0, 'errors')\n",
    "    label_cov = get_label(detectors, event, estimator, 0, 'inv_fishers')\n",
    "    data = pd.read_csv(PATH_TO_RESULTS + 'gwfish_medians/' + event + '/' + label_err, names = lbs_errs, delimiter=' ', skiprows=1)\n",
    "    mns = data[params].iloc[0].to_numpy()\n",
    "    cov = np.load(PATH_TO_RESULTS + 'gwfish_medians/' + event +'/' + label_cov)[0, :, :]\n",
    "    samples_tmvn = get_samples_from_TMVN(min_array, max_array, mns, cov, samples_len[event])\n",
    "    new_df = pd.DataFrame(samples_tmvn.T, columns = params)\n",
    "    posteriors = get_posteriors(new_df, my_priors[event], samples_len[event])\n",
    "    posteriors_df = pd.DataFrame(posteriors, columns = params)\n",
    "    posteriors_df.to_hdf(PATH_TO_RESULTS + 'posterior_samples/fisher_plus_priors_samples/fisher_plus_priors_samples_%s_%s.hdf5' %(estimator, event), mode='w', key='root')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
